{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1yf2Ij5Z6sBef7OXWMg8QbAwgBI0EZMTk","authorship_tag":"ABX9TyPiE43i1OgvQXIlz0liNTfN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0fd96ad152c445e981f1c2be5ddf07b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_462149fb3a6b49d19a8d2b3418359b32","IPY_MODEL_9eae4645c22f4e24a5db8da8256a7cc2","IPY_MODEL_cfb8007964bc4c2baa54d5c6c808738d"],"layout":"IPY_MODEL_707d8a4938344e5b87e2c6b07ef1fd35"}},"462149fb3a6b49d19a8d2b3418359b32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3b2165c9c504ac29c30a23724383e5a","placeholder":"​","style":"IPY_MODEL_8a778f4d90744ab5b1815a18671a8b77","value":"model.safetensors: 100%"}},"9eae4645c22f4e24a5db8da8256a7cc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a41a90bca44bbe8b57213ac2ce0cd7","max":2354805470,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d43ebe9e53b841dd9492555d9c704314","value":2354805470}},"cfb8007964bc4c2baa54d5c6c808738d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c99c258712b48b9a4a7586639b39fb0","placeholder":"​","style":"IPY_MODEL_80997f3abea14fb093b52b85ec578d4a","value":" 2.35G/2.35G [00:20&lt;00:00, 193MB/s]"}},"707d8a4938344e5b87e2c6b07ef1fd35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b2165c9c504ac29c30a23724383e5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a778f4d90744ab5b1815a18671a8b77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97a41a90bca44bbe8b57213ac2ce0cd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d43ebe9e53b841dd9492555d9c704314":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c99c258712b48b9a4a7586639b39fb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80997f3abea14fb093b52b85ec578d4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d13f080aa8ed454e9718d503e40c0546":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fba813a9efe048cbbb5d09419cd650e6","IPY_MODEL_e2fb6af66f994fc58ecad99ee952043e","IPY_MODEL_8964a0fbd17544e3871d9f5ab1ca1bfd"],"layout":"IPY_MODEL_a9bc19415211402a8967f66755305a90"}},"fba813a9efe048cbbb5d09419cd650e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e83b2ff046be43278ab90f79580c5264","placeholder":"​","style":"IPY_MODEL_35e8dc6abec849b8bb009c817d4394f6","value":"generation_config.json: 100%"}},"e2fb6af66f994fc58ecad99ee952043e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09fcef78f2749cf90d7ca78ff6c888b","max":234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0e1e4b3a73c4cedbd7982eed3603976","value":234}},"8964a0fbd17544e3871d9f5ab1ca1bfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42571937b87a448794960c4c47e40b46","placeholder":"​","style":"IPY_MODEL_d3343550f23f4f5282f386615f78a0c0","value":" 234/234 [00:00&lt;00:00, 21.1kB/s]"}},"a9bc19415211402a8967f66755305a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e83b2ff046be43278ab90f79580c5264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35e8dc6abec849b8bb009c817d4394f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b09fcef78f2749cf90d7ca78ff6c888b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0e1e4b3a73c4cedbd7982eed3603976":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42571937b87a448794960c4c47e40b46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3343550f23f4f5282f386615f78a0c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"lnqMjJpGclg8","executionInfo":{"status":"ok","timestamp":1751281491046,"user_tz":-330,"elapsed":46963,"user":{"displayName":"yagav yagav","userId":"06810115542901818551"}}},"outputs":[],"source":["%%capture\n","import os\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth\n","else:\n","    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n","    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n","    !pip install transformers==4.51.3\n","    !pip install --no-deps unsloth"]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"drive/MyDrive/vit_FineTune_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = 2048,\n","        dtype = None,\n","        load_in_4bit = True,\n",")\n","\n","FastLanguageModel.for_inference(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0fd96ad152c445e981f1c2be5ddf07b1","462149fb3a6b49d19a8d2b3418359b32","9eae4645c22f4e24a5db8da8256a7cc2","cfb8007964bc4c2baa54d5c6c808738d","707d8a4938344e5b87e2c6b07ef1fd35","a3b2165c9c504ac29c30a23724383e5a","8a778f4d90744ab5b1815a18671a8b77","97a41a90bca44bbe8b57213ac2ce0cd7","d43ebe9e53b841dd9492555d9c704314","5c99c258712b48b9a4a7586639b39fb0","80997f3abea14fb093b52b85ec578d4a","d13f080aa8ed454e9718d503e40c0546","fba813a9efe048cbbb5d09419cd650e6","e2fb6af66f994fc58ecad99ee952043e","8964a0fbd17544e3871d9f5ab1ca1bfd","a9bc19415211402a8967f66755305a90","e83b2ff046be43278ab90f79580c5264","35e8dc6abec849b8bb009c817d4394f6","b09fcef78f2749cf90d7ca78ff6c888b","a0e1e4b3a73c4cedbd7982eed3603976","42571937b87a448794960c4c47e40b46","d3343550f23f4f5282f386615f78a0c0"]},"id":"IWhaKUs1ctnB","executionInfo":{"status":"ok","timestamp":1751281580433,"user_tz":-330,"elapsed":84748,"user":{"displayName":"yagav yagav","userId":"06810115542901818551"}},"outputId":"70aa4db4-7842-45e3-980d-2c498de4a790"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.6.8: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fd96ad152c445e981f1c2be5ddf07b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d13f080aa8ed454e9718d503e40c0546"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unsloth 2025.6.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"]},{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): LlamaForCausalLM(\n","      (model): LlamaModel(\n","        (embed_tokens): Embedding(128256, 3072, padding_idx=128004)\n","        (layers): ModuleList(\n","          (0): LlamaDecoderLayer(\n","            (self_attn): LlamaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8192, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8192, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8192, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n","          )\n","          (1): LlamaDecoderLayer(\n","            (self_attn): LlamaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8192, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=3072, out_features=8192, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8192, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=8192, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8192, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n","          )\n","          (2-27): 26 x LlamaDecoderLayer(\n","            (self_attn): LlamaAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): LlamaMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8192, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=8192, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8192, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n","            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n","          )\n","        )\n","        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer, skip_prompt = True)"],"metadata":{"id":"6oy8SXIjiswG","executionInfo":{"status":"ok","timestamp":1751282142137,"user_tz":-330,"elapsed":3,"user":{"displayName":"yagav yagav","userId":"06810115542901818551"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def infer(prompt):\n","  messages = [\n","      {\"role\": \"user\", \"content\": f\"{prompt}\"},\n","  ]\n","  inputs = tokenizer.apply_chat_template(\n","      messages,\n","      tokenize = True,\n","      add_generation_prompt = True,\n","      return_tensors = \"pt\",\n","  ).to(\"cuda\")\n","\n","  _ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n","                    use_cache = True, temperature = 0.3, top_p = 0.9, do_sample = False)"],"metadata":{"id":"y3yQ9tX2c7kj","executionInfo":{"status":"ok","timestamp":1751282223996,"user_tz":-330,"elapsed":6,"user":{"displayName":"yagav yagav","userId":"06810115542901818551"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["infer(\"Tell me about Dr. Ganesan R\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTlkkxOrjNzp","executionInfo":{"status":"ok","timestamp":1751282283462,"user_tz":-330,"elapsed":2443,"user":{"displayName":"yagav yagav","userId":"06810115542901818551"}},"outputId":"df9a4061-3cdd-4895-f434-12252b7a07bb"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Highly probable that he is an associate professor in a technical field, with significant expertise in machine learning and natural language processing.<|eot_id|>\n"]}]}]}