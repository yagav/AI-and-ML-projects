{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11f00022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b049a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8375c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(\"Restaurant_Reviews.tsv\", quoting=3,delimiter='\\t')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed4814ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds['Review']\n",
    "y = ds['Liked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83092b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in X:\n",
    "    review = re.sub('[^a-zA-Z]',' ',i)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review]\n",
    "    corpus.append(\" \".join(review))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6eab2852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love thi place'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f68a587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(1000):\n",
    "    words = set(corpus[i].split())\n",
    "    features = {word:True for word in words}\n",
    "    train_data.append((features,y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9d950cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'place': True, 'love': True, 'thi': True, 'wow': True}, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef5dd300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (20 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.565\n",
      "             2          -0.54886        0.882\n",
      "             3          -0.46446        0.917\n",
      "             4          -0.40779        0.932\n",
      "             5          -0.36647        0.939\n",
      "             6          -0.33459        0.946\n",
      "             7          -0.30897        0.950\n",
      "             8          -0.28778        0.956\n",
      "             9          -0.26987        0.959\n",
      "            10          -0.25445        0.961\n",
      "            11          -0.24100        0.966\n",
      "            12          -0.22914        0.970\n",
      "            13          -0.21858        0.970\n",
      "            14          -0.20909        0.971\n",
      "            15          -0.20052        0.976\n",
      "            16          -0.19273        0.978\n",
      "            17          -0.18560        0.979\n",
      "            18          -0.17905        0.981\n",
      "            19          -0.17302        0.981\n",
      "         Final          -0.16743        0.983\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "X = train_data[:800]\n",
    "y = train_data[800:]\n",
    "cls = MaxentClassifier.train(X, max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e0ac24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = []\n",
    "for a,b in y:\n",
    "    y_real.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e722528",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "083e28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in y:\n",
    "    y_pred.append(cls.classify(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3062d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  47],\n",
       "       [  3,  45]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_real,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
